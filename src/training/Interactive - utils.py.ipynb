{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to .venv39 (3.9.22) (Python 3.9.22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cd256b-5d90-4c09-bd67-2527637163ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m/Users/pavankumar/Documents/Winter_Thesis/Coding_Learning/Master-Thesis/src/training/utils.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m13\u001b[39m, \u001b[39m14\u001b[39m, \u001b[39m15\u001b[39m], [\u001b[39m14\u001b[39m, \u001b[39m15\u001b[39m, \u001b[39m16\u001b[39m]])\n\u001b[1;32m      2\u001b[0m y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m17\u001b[39m, \u001b[39m18\u001b[39m, \u001b[39m19\u001b[39m], [\u001b[39m20\u001b[39m, \u001b[39m21\u001b[39m, \u001b[39m22\u001b[39m]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[13, 14, 15], [14, 15, 16]])\n",
    "y = torch.tensor([[17, 18, 19], [20, 21, 22]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da761e71-b59b-4a0d-915f-30b4e76a06fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will create the dat aloader and train test split and trained and evaluator.\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb4f902-43bc-4359-87d1-6ef4268671ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NeuralProcessDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m/Users/pavankumar/Documents/Winter_Thesis/Coding_Learning/Master-Thesis/src/training/utils.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m NeuralProcessDataset(x,y)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NeuralProcessDataset' is not defined"
     ]
    }
   ],
   "source": [
    "NeuralProcessDataset(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e035a0d7-b3c9-4ed8-b146-7dcdb7c98b08",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-4-6f2ef9920939>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    Creates context and target sets on the fly for Neural Processes.\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "class NeuralProcessDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Creates context and target sets on the fly for Neural Processes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, X, Y, min_context=10, max_context=50, min_target=50, max_target=100\n",
    "    ):\n",
    "        self.X = X  # Shape: [N, x_dim]\n",
    "        self.Y = Y  # Shape: [N, y_dim]\n",
    "        self.N = X.shape[0]\n",
    "\n",
    "        self.min_context = min_context\n",
    "        self.max_context = max_context\n",
    "        self.min_target = min_target\n",
    "        self.max_target = max_target\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of NP tasks per epoch\n",
    "        return 3000\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        perm = torch.randperm(self.N)\n",
    "\n",
    "        # Sample random sizes\n",
    "        C = torch.randint(self.min_context, self.max_context + 1, (1,)).item()\n",
    "        T = torch.randint(self.min_target, self.max_target + 1, (1,)).item()\n",
    "\n",
    "        # Select context\n",
    "        ctx_idx = perm[:C]\n",
    "        x_c = self.X[ctx_idx]  # [C, x_dim]\n",
    "        y_c = self.Y[ctx_idx]  # [C, y_dim]\n",
    "\n",
    "        # Select target\n",
    "        tgt_idx = perm[C : C + T]\n",
    "        x_t = self.X[tgt_idx]  # [T, x_dim]\n",
    "        y_t = self.Y[tgt_idx]  # [T, y_dim]\n",
    "\n",
    "        return x_c, y_c, x_t, y_t\n",
    "\n",
    "x = torch.tensor([[13, 14, 15], [14, 15, 16]])\n",
    "y = torch.tensor([[17, 18, 19], [20, 21, 22]])\n",
    "\n",
    "NeuralProcessDataset(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb666c0-9a47-46f5-83d4-a0da1319891b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NeuralProcessDataset at 0x10448a190>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_c = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "y_c = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
    "x_t = torch.tensor([[13, 14, 15], [14, 15, 16]])\n",
    "y_t = torch.tensor([[17, 18, 19], [20, 21, 22]])\n",
    "\n",
    "\"\"\"\n",
    "From this below class we will split the data sets in to context and targets.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class NeuralProcessDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Creates context and target sets on the fly for Neural Processes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, X, Y, min_context=10, max_context=50, min_target=50, max_target=100\n",
    "    ):\n",
    "        self.X = X  # Shape: [N, x_dim]\n",
    "        self.Y = Y  # Shape: [N, y_dim]\n",
    "        self.N = X.shape[0]\n",
    "\n",
    "        self.min_context = min_context\n",
    "        self.max_context = max_context\n",
    "        self.min_target = min_target\n",
    "        self.max_target = max_target\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of NP tasks per epoch\n",
    "        return 3000\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        perm = torch.randperm(self.N)\n",
    "\n",
    "        # Sample random sizes\n",
    "        C = torch.randint(self.min_context, self.max_context + 1, (1,)).item()\n",
    "        T = torch.randint(self.min_target, self.max_target + 1, (1,)).item()\n",
    "\n",
    "        # Select context\n",
    "        ctx_idx = perm[:C]\n",
    "        x_c = self.X[ctx_idx]  # [C, x_dim]\n",
    "        y_c = self.Y[ctx_idx]  # [C, y_dim]\n",
    "\n",
    "        # Select target\n",
    "        tgt_idx = perm[C : C + T]\n",
    "        x_t = self.X[tgt_idx]  # [T, x_dim]\n",
    "        y_t = self.Y[tgt_idx]  # [T, y_dim]\n",
    "\n",
    "        return x_c, y_c, x_t, y_t\n",
    "\n",
    "x = torch.tensor([[13, 14, 15], [14, 15, 16]])\n",
    "y = torch.tensor([[17, 18, 19], [20, 21, 22]])\n",
    "\n",
    "NeuralProcessDataset(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99946af5-0b6c-4b7f-aa99-63a6b73f19df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NeuralProcessDataset.__getitem__ of <__main__.NeuralProcessDataset object at 0x30f30c9d0>>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeuralProcessDataset(x,y).__getitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10165d24-7c47-475c-95e5-274de3857016",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__getitem__() missing 1 required positional argument: 'idx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m/Users/pavankumar/Documents/Winter_Thesis/Coding_Learning/Master-Thesis/src/training/utils.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m NeuralProcessDataset(x,y)\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m()\n",
      "\u001b[0;31mTypeError\u001b[0m: __getitem__() missing 1 required positional argument: 'idx'"
     ]
    }
   ],
   "source": [
    "NeuralProcessDataset(x,y).__getitem__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d25928d-0934-4ae6-828e-68dc531f722a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[13, 14, 15],\n",
       "         [14, 15, 16]]),\n",
       " tensor([[17, 18, 19],\n",
       "         [20, 21, 22]]),\n",
       " tensor([], size=(0, 3), dtype=torch.int64),\n",
       " tensor([], size=(0, 3), dtype=torch.int64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeuralProcessDataset(x,y).__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608bb82-12cc-4d2f-98b3-2c436513a8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17, 18, 19],\n",
       "        [20, 21, 22]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeuralProcessDataset(x,y).__getitem__(0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa523c61-efe4-4540-b207-fbc0ee9b360c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 3), dtype=torch.int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeuralProcessDataset(x,y).__getitem__(0)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e838e-c439-4ffc-a327-96c3f098e811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f74af3-89b9-49cd-8e33-bf99254239d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dec454-7da3-40ee-8b80-cb016f3b8751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c84384c-c3c6-48e1-a61d-0cdccd5eaba1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboard'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m/Users/pavankumar/Documents/Winter_Thesis/Coding_Learning/Master-Thesis/src/training/utils.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorboard\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m SummaryWriter\n",
      "File \u001b[0;32m~/Documents/Winter_Thesis/Coding_Learning/Master-Thesis/.venv39/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorboard\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mdistutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m LooseVersion\n\u001b[1;32m      4\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(tensorboard, \u001b[39m\"\u001b[39m\u001b[39m__version__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m LooseVersion(\n\u001b[1;32m      5\u001b[0m     tensorboard\u001b[39m.\u001b[39m__version__\n\u001b[1;32m      6\u001b[0m ) \u001b[39m<\u001b[39m LooseVersion(\u001b[39m\"\u001b[39m\u001b[39m1.15\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard'"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edf620f-dca1-4d25-bc68-ff22db97452c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboard'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m/Users/pavankumar/Documents/Winter_Thesis/Coding_Learning/Master-Thesis/src/training/utils.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorboard\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m SummaryWriter\n",
      "File \u001b[0;32m~/Documents/Winter_Thesis/Coding_Learning/Master-Thesis/.venv39/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorboard\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mdistutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m LooseVersion\n\u001b[1;32m      4\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(tensorboard, \u001b[39m\"\u001b[39m\u001b[39m__version__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m LooseVersion(\n\u001b[1;32m      5\u001b[0m     tensorboard\u001b[39m.\u001b[39m__version__\n\u001b[1;32m      6\u001b[0m ) \u001b[39m<\u001b[39m LooseVersion(\u001b[39m\"\u001b[39m\u001b[39m1.15\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard'"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv39 (3.9.22)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
