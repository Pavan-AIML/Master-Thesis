{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to .venv39 (3.9.22) (Python 3.9.22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea7258d-c9c8-477c-b36a-1d81162df959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pavankumar/Documents/Winter_Thesis/Coding_Learning/Master-Thesis\n",
      "/Users/pavankumar/Documents/Winter_Thesis/Coding_Learning/Master-Thesis\n",
      "{'dataset_num_1': 1, 'dataset_num_2': 2, 'dataset_num_3': 3, 'exp_name': 'aod_pm25_prediction', 'input_type_1': 1, 'input_type_2': 2, 'input_type_3': 3, 'input_type_4': 4, 'target_type': ['AOD', 'PM2.5'], 'input_vars': {1: ['latitude', 'longitude', 'AOD', 'PM2.5'], 2: ['latitude', 'longitude', 'AOD'], 3: ['latitude', 'longitude', 'PM2.5'], 4: ['latitude', 'longitude']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pavankumar/Documents/Winter_Thesis/Coding_Learning/Master-Thesis/.venv39/lib/python3.9/site-packages/lightning/fabric/__init__.py:36: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pavankumar/Documents/Winter_Thesis/Coding_Learning/Master-Thesis\n",
      "/Users/pavankumar/Documents/Winter_Thesis/Coding_Learning/Master-Thesis\n",
      "/Users/pavankumar/Documents/Winter_Thesis/Coding_Learning/Master-Thesis\n",
      "Extracting daily Pm2.5 data..\n",
      " daily_PM_data shape: (40, 1095)\n",
      "Fusing AOD data from multiple years...\n",
      " AOD_final shape: (1350, 1098)\n",
      "Finding nearest neighbours for PM2.5 stations...\n",
      "nearest_neighbours shape: (40, 1098)\n",
      "Cleaning data and handling missing values...\n",
      "Cleaned nearest_neighbours shape: (40, 1097)\n",
      "Preparing final training data...\n",
      "final_training_data shape: (15667, 5)\n",
      "Extracting daily Pm2.5 data..\n",
      " daily_PM_data shape: (40, 1095)\n",
      "Fusing AOD data from multiple years...\n",
      " AOD_final shape: (1350, 1098)\n",
      "Finding nearest neighbours for PM2.5 stations...\n",
      "nearest_neighbours shape: (40, 1098)\n",
      "Cleaning data and handling missing values...\n",
      "Cleaned nearest_neighbours shape: (40, 1097)\n",
      "Preparing final training data...\n",
      "final_training_data shape: (15667, 5)\n",
      "Extracting daily Pm2.5 data..\n",
      " daily_PM_data shape: (40, 1095)\n",
      "Fusing AOD data from multiple years...\n",
      " AOD_final shape: (1350, 1098)\n",
      "Finding nearest neighbours for PM2.5 stations...\n",
      "nearest_neighbours shape: (40, 1098)\n",
      "Cleaning data and handling missing values...\n",
      "Cleaned nearest_neighbours shape: (40, 1097)\n",
      "Preparing final training data...\n",
      "final_training_data shape: (15667, 5)\n",
      "Extracting daily Pm2.5 data..\n",
      " daily_PM_data shape: (40, 1095)\n",
      "Fusing AOD data from multiple years...\n",
      " AOD_final shape: (1350, 1098)\n",
      "Finding nearest neighbours for PM2.5 stations...\n",
      "nearest_neighbours shape: (40, 1098)\n",
      "Cleaning data and handling missing values...\n",
      "Cleaned nearest_neighbours shape: (40, 1097)\n",
      "Preparing final training data...\n",
      "final_training_data shape: (15667, 5)\n",
      "0 torch.Size([12307, 128])\n",
      "1 torch.Size([12307, 2])\n",
      "/Users/pavankumar/Documents/Winter_Thesis/Coding_Learning/Master-Thesis\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 2])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Importing the necessary packages.............\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import arrow\n",
    "from datetime import datetime\n",
    "\n",
    "# from utils.config import config\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ROOT = Path(__file__).resolve().parents[2]  # tests/ -> project root\n",
    "sys.path.insert(0, str(ROOT))\n",
    "print(ROOT)\n",
    "\n",
    "from configs.utils import config\n",
    "\n",
    "# -------------************---------------------------------\n",
    "# loading all the data loaders here we will load the final data in torch.\n",
    "from Dataloader.Modis_Data_loader.PM25_data_loader_analysis import Modis_data_loader\n",
    "from Dataloader.Modis_Data_loader.PM25_data_loader_analysis import PM_25_dataloader\n",
    "from Dataloader.Modis_Data_loader.PM25_data_loader_analysis import (\n",
    "    combine_the_data_frames,\n",
    ")\n",
    "from Dataloader.Modis_Data_loader.PM25_data_loader_analysis import Training_data_loader\n",
    "from locationencoder.final_location_encoder import Geospatial_Encoder\n",
    "from Dataloader.Modis_Data_loader.torch_data_loader import (\n",
    "    AirQualityDataset_latlon_AOD_PM25,\n",
    "    AirQualityDataset_latlon_AOD,\n",
    "    AirQualityDataset_latlon_PM25,\n",
    "    AirQualityDataset_latlon,\n",
    ")\n",
    "\n",
    "# importing config files\n",
    "from Dataloader.Modis_data_analysis.final_loader import (\n",
    "    Final_Air_Quality_Dataset_pipeline_latlon_AOD_PM25,\n",
    "    Final_Air_Quality_Dataset_pipeline_latlon_AOD,\n",
    "    Final_Air_Quality_Dataset_pipeline_latlon_PM25,\n",
    "    Final_Air_Quality_Dataset_pipeline_latlon,\n",
    ")\n",
    "\n",
    "# importing the loss function\n",
    "from loss_functions import LossFunctions\n",
    "\n",
    "\n",
    "# -------------************--------------------------------\n",
    "# Creating all the instance here\n",
    "\n",
    "instance_latlon_AOD_PM25 = Final_Air_Quality_Dataset_pipeline_latlon_AOD_PM25(config)\n",
    "instance_latlon_AOD = Final_Air_Quality_Dataset_pipeline_latlon_AOD(config)\n",
    "instance_latlon_PM25 = Final_Air_Quality_Dataset_pipeline_latlon_PM25(config)\n",
    "intance_latlon = Final_Air_Quality_Dataset_pipeline_latlon(config)\n",
    "\n",
    "\n",
    "# final data with latitude, longitude, AOD and PM2.5\n",
    "instance_latlon_AOD_PM25.modis_data_sets()\n",
    "instance_latlon_AOD_PM25.stations_data_sets()\n",
    "instance_latlon_AOD_PM25.PM_25_data()\n",
    "instance_latlon_AOD_PM25.training_data()\n",
    "instance_latlon_AOD_PM25.Torch_data()\n",
    "final_data_latlong_AOD_PM25 = instance_latlon_AOD_PM25.full_pipeline()\n",
    "len(final_data_latlong_AOD_PM25[0])\n",
    "\n",
    "final_data_latlong_AOD_PM25[1]\n",
    "# final data with latitude, longitude and AOD\n",
    "\n",
    "instance_latlon_AOD.modis_data_sets()\n",
    "instance_latlon_AOD.stations_data_sets()\n",
    "instance_latlon_AOD.PM_25_data()\n",
    "instance_latlon_AOD.training_data()\n",
    "instance_latlon_AOD.Torch_data()\n",
    "final_data_latlong_AOD = instance_latlon_AOD.full_pipeline()\n",
    "final_data_latlong_AOD[0]\n",
    "final_data_latlong_AOD[1][0]\n",
    "\n",
    "# final data with latitude, longitude  and PM2.5\n",
    "instance_latlon_PM25.modis_data_sets()\n",
    "instance_latlon_PM25.stations_data_sets()\n",
    "instance_latlon_PM25.PM_25_data()\n",
    "instance_latlon_PM25.training_data()\n",
    "instance_latlon_PM25.Torch_data()\n",
    "final_data_latlong_PM25 = instance_latlon_PM25.full_pipeline()\n",
    "final_data_latlong_PM25[0].shape\n",
    "final_data_latlong_PM25[1]\n",
    "\n",
    "# final data with latitude and longitude\n",
    "intance_latlon.modis_data_sets()\n",
    "intance_latlon.stations_data_sets()\n",
    "intance_latlon.PM_25_data()\n",
    "intance_latlon.training_data()\n",
    "intance_latlon.Torch_data()\n",
    "final_data_latlong = intance_latlon.full_pipeline()\n",
    "final_data_latlong[0].shape\n",
    "final_data_latlong[1][0]\n",
    "\n",
    "\n",
    "# -------------************--------------------------------\n",
    "\"\"\"\n",
    "Final training data.................\n",
    "\"\"\"\n",
    "final_data_latlong_AOD_PM25\n",
    "\n",
    "final_data_latlong_AOD_PM25\n",
    "final_data_latlong_AOD[0].shape\n",
    "final_data_latlong_PM25[0].shape\n",
    "final_data_latlong[0].shape\n",
    "\n",
    "for i, t in enumerate(final_data_latlong_AOD_PM25):\n",
    "    print(i, t.shape)\n",
    "# final data sets wit x, y in torch tensor form\n",
    "final_data_latlong_AOD_PM25[0].shape\n",
    "x, y = final_data_latlong_AOD\n",
    "x.shape[0]\n",
    "final_data_latlong_PM25\n",
    "final_data_latlong\n",
    "\n",
    "\n",
    "# -------------************--------------------------------\n",
    "\n",
    "# training the model in different sdata sets and storing the weights.\n",
    "\n",
    "# -------------************--------------------------------\n",
    "\n",
    "# importing the model from model file.\n",
    "\"\"\"\n",
    "Importing the model................\n",
    "\"\"\"\n",
    "\n",
    "from src.Models.neural_process import NeuralProcess\n",
    "\n",
    "# self, x_c_dim, y_c_dim, x_t_dim, y_t_dim, hidden_dim, latent_dim\n",
    "# self, x_target_dim, z_dim, hidden_dim, y_target_dim\n",
    "# self, x_c_dim, y_c_dim, x_t_dim, y_t_dim, hidden_dim, latent_dim\n",
    "\n",
    "# Creating the models those are compatible with the all kinds of inputs.\n",
    "\n",
    "# -------------************---------------------------------\n",
    "\n",
    "\"\"\"\n",
    "Final models for training........... making attributes from the class\n",
    "\"\"\"\n",
    "\n",
    "model_latlon_AOD_PM25 = NeuralProcess(128, 2, 128, 2, 128, 128)\n",
    "model_latlon_AOD = NeuralProcess(127, 2, 127, 2, 128, 128)\n",
    "model_latlon_PM25 = NeuralProcess(127, 2, 127, 2, 128, 128)\n",
    "model_latlon = NeuralProcess(126, 2, 127, 2, 128, 128)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Here we will import the loss function...........\n",
    "\"\"\"\n",
    "# self, beta, learning_rate, stepsize, Number_of_steps, device#\n",
    "Loss = LossFunctions()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Now we have model, loss function, data from here we can build the model trainer that will train the model with the tensor board.\n",
    "\n",
    "The first & second class --: will devide the data in to chunks and also train, val and test this will create a final data loader. \n",
    "\n",
    "Third class --: this class will create the loop for train the network. \n",
    "\n",
    "Fourth class --: will validate the data set \n",
    "\n",
    "Fifth step --: will evaluate the model.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ------------ The first step is to devide the data in terms of context and test sets.\n",
    "\n",
    "\n",
    "from optimizer_utils import context_target_split\n",
    "\n",
    "C_T_data = context_target_split(\n",
    "    final_data_latlong_AOD_PM25[0].unsqueeze(0),\n",
    "    final_data_latlong_AOD_PM25[1].unsqueeze(0),\n",
    ")\n",
    "\n",
    "C_T_data[0].shape\n",
    "C_T_data[1].shape\n",
    "C_T_data[2].shape\n",
    "C_T_data[3].shape\n",
    "\n",
    "final_data_latlong_AOD_PM25[0].unsqueeze(0)[0]\n",
    "\n",
    "\"\"\" self,\n",
    "        model,\n",
    "        optimizer,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        log_dir=\"./logs\",\n",
    "        checkpoint_dir=\"./checkpoints\",\n",
    "\"\"\"\n",
    "\n",
    "# Importing the optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "Optimizer = optim.Adam(model_latlon_AOD_PM25.parameters(), lr=1e-4)\n",
    "\n",
    "# Importing the trainer\n",
    "\n",
    "final_data_latlong_AOD_PM25[0].__getitem__(10)\n",
    "# First data ser priority will be\n",
    "# def train_epoch(self, dataloader, epoch_idx):\n",
    "\n",
    "from optimizer_utils import neural_process_data\n",
    "# now to start training we need a data-loader that\n",
    "\n",
    "NeuralProcessData_latlon_AOD_PM25 = neural_process_data(\n",
    "    final_data_latlong_AOD_PM25[0],\n",
    "    final_data_latlong_AOD_PM25[1],\n",
    "    num_points_per_task=200,\n",
    ")\n",
    "\n",
    "X_task, Y_task = NeuralProcessData_latlon_AOD_PM25[0]\n",
    "X_task.shape\n",
    "Y_task.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3a79eb-1e12-4f78-a33b-08cf02092df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.8213, -1.2706, -0.4533,  ..., -0.2197,  0.9654,  1.2592],\n",
       "         [ 0.8213, -1.2706, -0.4533,  ..., -0.2197, -0.7220, -0.0482],\n",
       "         [ 0.8213, -1.2706, -0.4533,  ..., -0.2197, -0.3033, -0.1231],\n",
       "         ...,\n",
       "         [ 0.8200, -1.2679, -0.4557,  ..., -0.2200, -0.5858, -0.2545],\n",
       "         [ 0.8200, -1.2679, -0.4557,  ..., -0.2200,  0.4649, -0.3712],\n",
       "         [ 0.8200, -1.2679, -0.4557,  ..., -0.2200, -0.4296,  0.0278]],\n",
       "        grad_fn=<CatBackward0>),\n",
       " tensor([[ 0.9654,  1.2592],\n",
       "         [-0.7220, -0.0482],\n",
       "         [-0.3033, -0.1231],\n",
       "         ...,\n",
       "         [-0.5858, -0.2545],\n",
       "         [ 0.4649, -0.3712],\n",
       "         [-0.4296,  0.0278]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_latlong_AOD_PM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5edaaf-1052-478e-bf3a-c8ee263e23df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8213, -1.2706, -0.4533,  ..., -0.2197,  0.9654,  1.2592],\n",
       "        [ 0.8213, -1.2706, -0.4533,  ..., -0.2197, -0.7220, -0.0482],\n",
       "        [ 0.8213, -1.2706, -0.4533,  ..., -0.2197, -0.3033, -0.1231],\n",
       "        ...,\n",
       "        [ 0.8200, -1.2679, -0.4557,  ..., -0.2200, -0.5858, -0.2545],\n",
       "        [ 0.8200, -1.2679, -0.4557,  ..., -0.2200,  0.4649, -0.3712],\n",
       "        [ 0.8200, -1.2679, -0.4557,  ..., -0.2200, -0.4296,  0.0278]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_latlong_AOD_PM25[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9705ffb3-fc7c-4261-9802-15713e15a1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.8213, -1.2706, -0.4533,  ..., -0.2197,  0.9654,  1.2592],\n",
       "         [ 0.8213, -1.2706, -0.4533,  ..., -0.2197, -0.7220, -0.0482],\n",
       "         [ 0.8213, -1.2706, -0.4533,  ..., -0.2197, -0.3033, -0.1231],\n",
       "         ...,\n",
       "         [ 0.8200, -1.2679, -0.4557,  ..., -0.2200, -0.5858, -0.2545],\n",
       "         [ 0.8200, -1.2679, -0.4557,  ..., -0.2200,  0.4649, -0.3712],\n",
       "         [ 0.8200, -1.2679, -0.4557,  ..., -0.2200, -0.4296,  0.0278]],\n",
       "        grad_fn=<CatBackward0>),\n",
       " tensor([[ 0.9654,  1.2592],\n",
       "         [-0.7220, -0.0482],\n",
       "         [-0.3033, -0.1231],\n",
       "         ...,\n",
       "         [-0.5858, -0.2545],\n",
       "         [ 0.4649, -0.3712],\n",
       "         [-0.4296,  0.0278]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_latlong_AOD_PM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e0d93-51c8-40cc-94a7-36708733d5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.2384,  0.5588, -0.0965,  ...,  0.3799,  0.1579,  0.1248],\n",
       "         [ 1.2384,  0.5588, -0.0965,  ...,  0.3799,  0.1579,  0.1248],\n",
       "         [ 1.2384,  0.5588, -0.0965,  ...,  0.3799,  0.1579,  0.1248],\n",
       "         ...,\n",
       "         [ 1.2386,  0.5598, -0.0965,  ...,  0.3793,  0.1597,  0.1252],\n",
       "         [ 1.2386,  0.5598, -0.0965,  ...,  0.3793,  0.1597,  0.1252],\n",
       "         [ 1.2386,  0.5598, -0.0965,  ...,  0.3793,  0.1597,  0.1252]],\n",
       "        grad_fn=<CatBackward0>),\n",
       " tensor([[  1.2280, 225.3438],\n",
       "         [  0.5470, 112.8750],\n",
       "         [  0.7160, 106.4375],\n",
       "         ...,\n",
       "         [  0.6020,  95.1299],\n",
       "         [  1.0260,  85.0938],\n",
       "         [  0.6650, 119.4167]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_latlong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31f186a-95ca-4d5a-82d9-ebb886242e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = final_data_latlong_AOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cba36a3-0ed3-4ba2-a7f4-edb8ac3f3dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12307"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc38bb-4e9d-46b6-88bd-ca231206e85a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-a2885923daf8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    x.\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8411a1f-47d3-476b-b79b-2e63f4670e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7793,  1.3130, -0.5150,  ..., -1.1960,  0.8817,  1.2280],\n",
       "        [-0.7793,  1.3130, -0.5150,  ..., -1.1960,  0.8817,  0.5470],\n",
       "        [-0.7793,  1.3130, -0.5150,  ..., -1.1960,  0.8817,  0.7160],\n",
       "        ...,\n",
       "        [-0.7818,  1.3116, -0.5153,  ..., -1.1917,  0.8828,  0.6020],\n",
       "        [-0.7818,  1.3116, -0.5153,  ..., -1.1917,  0.8828,  1.0260],\n",
       "        [-0.7818,  1.3116, -0.5153,  ..., -1.1917,  0.8828,  0.6650]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef1f34-c595-4eaf-aeee-521ec71cb418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Models.neural_process import NeuralProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc32d8e-e631-4949-90ac-4558af12c0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_latlon_AOD_PM25 = NeuralProcess(128, 2, 128, 2, 128, 128)\n",
    "model_latlon_AOD = NeuralProcess(127, 2, 127, 2, 128, 128)\n",
    "model_latlon_PM25 = NeuralProcess(127, 2, 127, 2, 128, 128)\n",
    "model_latlon = NeuralProcess(126, 2, 127, 2, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb64f9b-6b5d-4877-82bd-e04bd87093f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = LossFunctions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e31900-d844-47ad-ac87-9040b7b68262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizer_utils import context_target_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac75ba7-5ae7-44de-a6ef-31f95d2e5f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_T_data = context_target_split(\n",
    "    final_data_latlong_AOD_PM25[0].unsqueeze(0),\n",
    "    final_data_latlong_AOD_PM25[1].unsqueeze(0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2482f1f4-1586-4070-81eb-5c0342e4a99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_T_data[0].shape\n",
    "C_T_data[1].shape\n",
    "C_T_data[2].shape\n",
    "C_T_data[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71742f31-9cd9-49a8-8da1-59e539c70051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8213, -1.2706, -0.4533,  ..., -0.2197,  0.9654,  1.2592],\n",
       "        [ 0.8213, -1.2706, -0.4533,  ..., -0.2197, -0.7220, -0.0482],\n",
       "        [ 0.8213, -1.2706, -0.4533,  ..., -0.2197, -0.3033, -0.1231],\n",
       "        ...,\n",
       "        [ 0.8200, -1.2679, -0.4557,  ..., -0.2200, -0.5858, -0.2545],\n",
       "        [ 0.8200, -1.2679, -0.4557,  ..., -0.2200,  0.4649, -0.3712],\n",
       "        [ 0.8200, -1.2679, -0.4557,  ..., -0.2200, -0.4296,  0.0278]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_latlong_AOD_PM25[0].unsqueeze(0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aa729f-27ce-463c-9941-3fa650479520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111adafe-25f0-4621-940b-c6ae3a500e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimizer = optim.Adam(model_latlon_AOD_PM25.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a35d6-3a5d-450e-be5d-7a898a0100d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.2131e-01, -1.2706e+00, -4.5331e-01,  2.9036e-01, -1.2760e+00,\n",
       "        -3.9974e-01,  1.8594e+00,  1.1703e+00, -1.8606e-05,  5.2758e-01,\n",
       "         1.3764e+00, -1.1656e+00,  8.9693e-01,  1.8188e-01,  2.2443e+00,\n",
       "        -1.0425e+00,  3.8400e-01,  1.2789e+00,  3.3677e-01, -1.8441e-01,\n",
       "         2.4959e-01,  1.2210e+00, -2.5053e-01, -4.3350e-01,  1.8787e-01,\n",
       "         5.5356e-01,  2.6125e-01,  5.6281e-01, -3.3981e-01,  1.6208e+00,\n",
       "        -2.6066e-01,  5.3954e-01,  5.3861e-01, -7.1402e-01,  1.0262e-01,\n",
       "        -4.3640e-01,  4.7413e-01, -8.6633e-01,  1.5694e-01,  3.8956e-02,\n",
       "        -3.2202e-02, -4.6373e-01, -2.5426e-01, -9.5811e-01, -2.9337e-03,\n",
       "        -3.0596e-01,  5.8505e-01,  3.5150e-01, -9.1359e-02,  5.6125e-01,\n",
       "         4.2494e-01, -8.4200e-01,  6.8421e-01, -2.4915e-01, -3.1594e-02,\n",
       "         7.5370e-01, -5.4094e-01, -1.1469e+00,  6.3201e-01, -4.4623e-01,\n",
       "        -1.9939e+00,  9.2838e-01, -1.9337e+00,  5.4995e-01,  9.0804e-03,\n",
       "         5.9840e-01,  7.6809e-01,  4.4503e-01, -1.7384e-01, -4.3640e-01,\n",
       "        -8.0870e-01,  6.5753e-01,  1.0489e+00, -7.2876e-03,  4.2642e-01,\n",
       "        -1.6733e+00,  1.1458e+00,  1.1265e+00,  2.7417e-01, -3.3388e-01,\n",
       "        -2.1242e-01,  1.1477e+00, -2.5165e+00,  1.1437e+00, -5.9862e-01,\n",
       "        -2.0564e-01, -4.6276e-01,  6.3653e-01,  7.6202e-01, -2.4621e-01,\n",
       "        -3.7507e-01,  1.3707e+00, -3.2245e-04,  6.9985e-02,  6.7665e-01,\n",
       "        -6.4711e-01,  6.2157e-02,  1.8319e+00, -1.0767e+00,  1.0650e+00,\n",
       "        -7.6056e-01,  1.9265e+00,  6.1571e-01, -1.5587e-01,  2.9350e-01,\n",
       "        -7.2707e-01,  2.2068e+00,  3.5100e-01,  3.5618e-01, -1.6053e+00,\n",
       "         4.3984e-01,  1.4333e-01, -5.0666e-01, -5.6254e-01,  6.5402e-01,\n",
       "        -2.7680e-01, -7.4784e-01, -5.5651e-02, -9.1254e-03, -4.2146e-01,\n",
       "         2.5837e-01,  1.0461e+00, -1.9217e-01, -3.9302e-01,  5.1630e-01,\n",
       "        -2.1975e-01, -7.4186e-01,  6.7501e-01], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_latlong_AOD_PM25[0].__getitem__(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e728a-a8dd-4ebf-9199-8d2af7d8c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizer_utils import neural_process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb4c994-2696-40dd-a2b9-a0b223c9c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralProcessData_latlon_AOD_PM25 = neural_process_data(\n",
    "    final_data_latlong_AOD_PM25[0],\n",
    "    final_data_latlong_AOD_PM25[1],\n",
    "    num_points_per_task=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7021cf8b-b929-4bfb-b497-813847f55d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_task, Y_task = NeuralProcessData_latlon_AOD_PM25[0]\n",
    "X_task.shape\n",
    "Y_task.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd51c81-b5de-4774-bf0f-5446c0159aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset=NeuralProcessData_latlon_AOD_PM25,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a930f44c-0eba-43e6-9764-83aaf6be0c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xb, Yb = next(iter(dataloader))\n",
    "Xb.shape, Yb.shape\n",
    "from optimizer_utils import NPTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e9349b-ae96-4203-9cfc-a275ebc45f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 200, 128]), torch.Size([16, 200, 2]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb.shape, Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b971389c-ff11-4973-8e9b-402e14fdb5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 200, 128]), torch.Size([16, 200, 2]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb.shape, Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6db443-22f2-476c-a658-ac981ced939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training = NPTrainer(\n",
    "    model=model_latlon_AOD_PM25,\n",
    "    optimizer=Optimizer,\n",
    "    loss_fn=Loss,\n",
    "    device=\"cpu\",\n",
    "    log_dir=\"./logs\",\n",
    "    checkpoint_dir=\"./checkpoints\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde10ce1-7895-48b1-93f9-d0aac106d16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 770/770 [00:12<00:00, 62.71it/s, Loss=-224.94]\n",
      "Epoch 1: 100%|██████████| 770/770 [00:11<00:00, 66.30it/s, Loss=-298.46]\n",
      "Epoch 2: 100%|██████████| 770/770 [00:11<00:00, 66.89it/s, Loss=-706.73]\n",
      "Epoch 3: 100%|██████████| 770/770 [00:11<00:00, 66.05it/s, Loss=nan]                   \n",
      "Epoch 4: 100%|██████████| 770/770 [00:11<00:00, 66.43it/s, Loss=nan]\n",
      "Epoch 5: 100%|██████████| 770/770 [00:11<00:00, 64.81it/s, Loss=nan]\n",
      "Epoch 6: 100%|██████████| 770/770 [00:11<00:00, 66.18it/s, Loss=nan]\n",
      "Epoch 7: 100%|██████████| 770/770 [00:11<00:00, 66.26it/s, Loss=nan]\n",
      "Epoch 8: 100%|██████████| 770/770 [00:11<00:00, 66.15it/s, Loss=nan]\n",
      "Epoch 9: 100%|██████████| 770/770 [00:11<00:00, 65.68it/s, Loss=nan]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    Training.train_epoch(dataloader, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad0501-2dde-4c9e-bcb0-65bd45542bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<optimizer_utils.neural_process_data at 0x107d311c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe3ecb9-bce1-4e09-b755-117fb072f86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<optimizer_utils.neural_process_data at 0x107d311c0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b1c1d1-eff1-4f00-9ffe-4fe6188ba37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<optimizer_utils.neural_process_data at 0x107d311c0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f2483-0be7-467a-bc78-50a47971e7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 200, 128]), torch.Size([16, 200, 2]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb.shape, Yb.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv39 (3.9.22)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
